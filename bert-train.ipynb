{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yas1nth/bert-train?scriptVersionId=154925913\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel, BertForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T00:13:01.474894Z","iopub.execute_input":"2023-12-14T00:13:01.475252Z","iopub.status.idle":"2023-12-14T00:13:07.360963Z","shell.execute_reply.started":"2023-12-14T00:13:01.475203Z","shell.execute_reply":"2023-12-14T00:13:07.360022Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"[](http://)","metadata":{}},{"cell_type":"code","source":"# load pre-trained BERT model and tokenizer\nmodel_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nnum_classes = 3\n# model = BertModel.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes) # num_classes is the number of sentiment classes\nmodel = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:07.36251Z","iopub.execute_input":"2023-12-14T00:13:07.362864Z","iopub.status.idle":"2023-12-14T00:13:16.651303Z","shell.execute_reply.started":"2023-12-14T00:13:07.362839Z","shell.execute_reply":"2023-12-14T00:13:16.650253Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1a6a31d67f54403b920734e8c488555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d4cf6473c2b4c5b928cd65c14064b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ce5d4c1f564b46bcc573d973fb7bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"670d4df0d40541509823192cd91b4086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b939fc6e533f456b8934ea347267f014"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:16.652578Z","iopub.execute_input":"2023-12-14T00:13:16.652902Z","iopub.status.idle":"2023-12-14T00:13:16.957678Z","shell.execute_reply.started":"2023-12-14T00:13:16.652875Z","shell.execute_reply":"2023-12-14T00:13:16.956879Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!wget https://gist.githubusercontent.com/kvyaswanth/29d2858f54642494aa86d1bdec0a3a3b/raw/b3697e379551fe523f05f40adc841a48dbbb120a/datasetSentences.csv\n!wget https://gist.githubusercontent.com/kvyaswanth/29d2858f54642494aa86d1bdec0a3a3b/raw/b3697e379551fe523f05f40adc841a48dbbb120a/datasetSplit.csv","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:16.95997Z","iopub.execute_input":"2023-12-14T00:13:16.960486Z","iopub.status.idle":"2023-12-14T00:13:19.35262Z","shell.execute_reply.started":"2023-12-14T00:13:16.960454Z","shell.execute_reply":"2023-12-14T00:13:19.351557Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2023-12-14 00:13:17--  https://gist.githubusercontent.com/kvyaswanth/29d2858f54642494aa86d1bdec0a3a3b/raw/b3697e379551fe523f05f40adc841a48dbbb120a/datasetSentences.csv\nResolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1290254 (1.2M) [text/plain]\nSaving to: ‘datasetSentences.csv’\n\ndatasetSentences.cs 100%[===================>]   1.23M  --.-KB/s    in 0.04s   \n\n2023-12-14 00:13:18 (34.9 MB/s) - ‘datasetSentences.csv’ saved [1290254/1290254]\n\n--2023-12-14 00:13:19--  https://gist.githubusercontent.com/kvyaswanth/29d2858f54642494aa86d1bdec0a3a3b/raw/b3697e379551fe523f05f40adc841a48dbbb120a/datasetSplit.csv\nResolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 83764 (82K) [text/plain]\nSaving to: ‘datasetSplit.csv’\n\ndatasetSplit.csv    100%[===================>]  81.80K  --.-KB/s    in 0.01s   \n\n2023-12-14 00:13:19 (5.61 MB/s) - ‘datasetSplit.csv’ saved [83764/83764]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('datasetSentences.csv')\nlabels = pd.read_csv('datasetSplit.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:19.354823Z","iopub.execute_input":"2023-12-14T00:13:19.355239Z","iopub.status.idle":"2023-12-14T00:13:19.394185Z","shell.execute_reply.started":"2023-12-14T00:13:19.355179Z","shell.execute_reply":"2023-12-14T00:13:19.393437Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def inp_ids(text):\n  return tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)['input_ids']\n\ndef token_types(text):\n  return tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)['token_type_ids']\n\ndef attn_mask(text):\n  return tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:19.395453Z","iopub.execute_input":"2023-12-14T00:13:19.396181Z","iopub.status.idle":"2023-12-14T00:13:19.402293Z","shell.execute_reply.started":"2023-12-14T00:13:19.396145Z","shell.execute_reply":"2023-12-14T00:13:19.401275Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['input_ids'] = df['sentence'].apply(inp_ids)\ndf['token_type_ids'] = df['sentence'].apply(token_types)\ndf['attention_mask'] = df['sentence'].apply(attn_mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:19.40366Z","iopub.execute_input":"2023-12-14T00:13:19.403946Z","iopub.status.idle":"2023-12-14T00:13:49.786143Z","shell.execute_reply.started":"2023-12-14T00:13:19.40391Z","shell.execute_reply":"2023-12-14T00:13:49.785156Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def extract_embeddings(row):\n    inputs = {\n        'input_ids': row['input_ids'].cuda(),\n        'token_type_ids': row['token_type_ids'].cuda(),\n        'attention_mask': row['attention_mask'].cuda()\n    }\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state\n        return embeddings.cpu().numpy()\n    \ndef pad_tensor(tensor, max_length):\n    padding_length = max_length - tensor.shape[1]\n    if padding_length > 0:\n        pad =(0, 0, 0, padding_length)\n        tensor = torch.nn.functional.pad(tensor, pad, \"constant\", 0)\n    return tensor","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.78751Z","iopub.execute_input":"2023-12-14T00:13:49.787885Z","iopub.status.idle":"2023-12-14T00:13:49.795447Z","shell.execute_reply.started":"2023-12-14T00:13:49.787851Z","shell.execute_reply":"2023-12-14T00:13:49.794527Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# df['embeddings'] = df[['input_ids','token_type_ids','attention_mask']].apply(extract_embeddings, axis=1)\n# max_length = max([tensor.shape[1] for tensor in df.embeddings])\n# X = [pad_tensor(torch.tensor(tensor), max_length) for tensor in df.embeddings]\n# X = torch.vstack(X)\n# X = [tensor.mean(dim=0) for tensor in X]\n# X = torch.vstack(X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.796589Z","iopub.execute_input":"2023-12-14T00:13:49.79689Z","iopub.status.idle":"2023-12-14T00:13:49.808497Z","shell.execute_reply.started":"2023-12-14T00:13:49.796864Z","shell.execute_reply":"2023-12-14T00:13:49.807608Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y = labels['splitset_label'].values - 1\nlabels['splitset_label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.811907Z","iopub.execute_input":"2023-12-14T00:13:49.812164Z","iopub.status.idle":"2023-12-14T00:13:49.835444Z","shell.execute_reply.started":"2023-12-14T00:13:49.812141Z","shell.execute_reply":"2023-12-14T00:13:49.834474Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"splitset_label\n1    8544\n2    2210\n3    1101\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.836452Z","iopub.execute_input":"2023-12-14T00:13:49.836723Z","iopub.status.idle":"2023-12-14T00:13:49.840969Z","shell.execute_reply.started":"2023-12-14T00:13:49.836699Z","shell.execute_reply":"2023-12-14T00:13:49.840064Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size = 1\nlearning_rate = 1e-5\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.842141Z","iopub.execute_input":"2023-12-14T00:13:49.842498Z","iopub.status.idle":"2023-12-14T00:13:49.851676Z","shell.execute_reply.started":"2023-12-14T00:13:49.842466Z","shell.execute_reply":"2023-12-14T00:13:49.850772Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df['splitset_label'] = labels['splitset_label']","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.852626Z","iopub.execute_input":"2023-12-14T00:13:49.852986Z","iopub.status.idle":"2023-12-14T00:13:49.863739Z","shell.execute_reply.started":"2023-12-14T00:13:49.852946Z","shell.execute_reply":"2023-12-14T00:13:49.862826Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def pad_attn_mask(tensor, max_length):\n    padding_length = max_length - tensor.shape[1]\n    if padding_length > 0:\n        pad =(0, padding_length)\n        tensor = torch.nn.functional.pad(tensor, pad, \"constant\", 0)\n    return tensor\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.864897Z","iopub.execute_input":"2023-12-14T00:13:49.865199Z","iopub.status.idle":"2023-12-14T00:13:49.874037Z","shell.execute_reply.started":"2023-12-14T00:13:49.865167Z","shell.execute_reply":"2023-12-14T00:13:49.873354Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Pad each tensor in the DataFrame\nmax_length = max([tensor.shape[1] for tensor in df.input_ids])\nx1 = [pad_attn_mask(torch.tensor(tensor), max_length) for tensor in df.input_ids]\nx1 = torch.vstack(x1)\n\nmax_length = max([tensor.shape[1] for tensor in df.attention_mask])\nx2 = [pad_attn_mask(torch.tensor(tensor), max_length) for tensor in df.attention_mask]\nx2 = torch.vstack(x2)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:49.875109Z","iopub.execute_input":"2023-12-14T00:13:49.875382Z","iopub.status.idle":"2023-12-14T00:13:50.342999Z","shell.execute_reply.started":"2023-12-14T00:13:49.875358Z","shell.execute_reply":"2023-12-14T00:13:50.342196Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/2433885622.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  x1 = [pad_attn_mask(torch.tensor(tensor), max_length) for tensor in df.input_ids]\n/tmp/ipykernel_42/2433885622.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  x2 = [pad_attn_mask(torch.tensor(tensor), max_length) for tensor in df.attention_mask]\n","output_type":"stream"}]},{"cell_type":"code","source":"for item in (x1,x2):\n    print(item[0].shape,item[1].shape)\n    break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-14T00:13:50.344769Z","iopub.execute_input":"2023-12-14T00:13:50.345061Z","iopub.status.idle":"2023-12-14T00:13:50.35017Z","shell.execute_reply.started":"2023-12-14T00:13:50.345035Z","shell.execute_reply":"2023-12-14T00:13:50.349375Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"torch.Size([80]) torch.Size([80])\n","output_type":"stream"}]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Instantiate SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\n\n# Apply SMOTE to the data\nX_resampled, y_resampled = smote.fit_resample(x1, y)\n\nxtrain, valtrain, ytrain, yval = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n\n# Instantiate SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\n\n# Apply SMOTE to the data\nX_resampled, y_resampled = smote.fit_resample(x2, y)\n\n\nmasktrain, maskval, _, _ = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:50.351418Z","iopub.execute_input":"2023-12-14T00:13:50.351695Z","iopub.status.idle":"2023-12-14T00:13:52.113023Z","shell.execute_reply.started":"2023-12-14T00:13:50.351671Z","shell.execute_reply":"2023-12-14T00:13:52.111567Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# dataset = TensorDataset(x1.cuda(), x2.cuda(), torch.tensor(y).cuda())\n# train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:52.11546Z","iopub.execute_input":"2023-12-14T00:13:52.116767Z","iopub.status.idle":"2023-12-14T00:13:52.126368Z","shell.execute_reply.started":"2023-12-14T00:13:52.116709Z","shell.execute_reply":"2023-12-14T00:13:52.12519Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_inputs = torch.tensor(xtrain)\nvalidation_inputs = torch.tensor(valtrain)\n\ntrain_labels = torch.tensor(ytrain)\nvalidation_labels = torch.tensor(yval)\n\ntrain_masks = torch.tensor(masktrain)\nvalidation_masks = torch.tensor(maskval)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:52.127988Z","iopub.execute_input":"2023-12-14T00:13:52.129483Z","iopub.status.idle":"2023-12-14T00:13:52.16561Z","shell.execute_reply.started":"2023-12-14T00:13:52.129339Z","shell.execute_reply":"2023-12-14T00:13:52.164698Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#Creating the DataLoader which will help us to load data into the GPU/CPU\nbatch_size = 32*3\n\n# Create the DataLoader for our training set.\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n\n# Create the DataLoader for our validation set.\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, shuffle=True, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:13:52.166819Z","iopub.execute_input":"2023-12-14T00:13:52.167709Z","iopub.status.idle":"2023-12-14T00:13:52.178689Z","shell.execute_reply.started":"2023-12-14T00:13:52.167673Z","shell.execute_reply":"2023-12-14T00:13:52.17752Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"total_loss = 0\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    for idx,batch in enumerate(train_dataloader):\n        inputs, attention_mask, targets = batch[0].cuda(),batch[1].cuda(),batch[2].cuda()\n#         inputs, attention_mask, targets = batch#[0].cuda(),batch[1].cuda(),batch[2].cuda()\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask, labels=targets)\n        loss = outputs[0]\n        total_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        \n    print(\"epoch\", epoch,  \"| loss\", loss)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-14T00:13:52.180194Z","iopub.execute_input":"2023-12-14T00:13:52.180809Z","iopub.status.idle":"2023-12-14T00:47:25.07981Z","shell.execute_reply.started":"2023-12-14T00:13:52.180774Z","shell.execute_reply":"2023-12-14T00:47:25.077978Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"epoch 0 | loss tensor(0.8281, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 1 | loss tensor(0.7657, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 2 | loss tensor(0.6950, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 3 | loss tensor(0.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 4 | loss tensor(0.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 5 | loss tensor(0.6881, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 6 | loss tensor(0.5479, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 7 | loss tensor(0.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 8 | loss tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 9 | loss tensor(0.1715, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 10 | loss tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 11 | loss tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\nepoch 13 | loss tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m| loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"preds = []\nact = []\nwith torch.no_grad():\n    for idx,batch in enumerate(validation_dataloader):\n        act.append(batch[2].numpy())\n        inputs, attention_mask = batch[0].cuda(),batch[1].cuda()\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask)\n        preds.append(outputs.logits.detach().cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:47:27.690013Z","iopub.execute_input":"2023-12-14T00:47:27.690802Z","iopub.status.idle":"2023-12-14T00:47:39.709266Z","shell.execute_reply.started":"2023-12-14T00:47:27.690764Z","shell.execute_reply":"2023-12-14T00:47:39.708019Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from torch.nn.functional import softmax\n\n# Assuming `logits` is the output from your model and has shape [batch_size, num_classes]\ntmp_logits = torch.tensor(np.vstack(preds))\nprobabilities = softmax(tmp_logits, dim=1)  # Apply softmax to convert logits to probabilities\npredicted_labels = torch.argmax(probabilities, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:47:39.711043Z","iopub.execute_input":"2023-12-14T00:47:39.71136Z","iopub.status.idle":"2023-12-14T00:47:39.724341Z","shell.execute_reply.started":"2023-12-14T00:47:39.711333Z","shell.execute_reply":"2023-12-14T00:47:39.723565Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"act_labels = []\nfor arr in act:\n    act_labels.extend(arr.tolist())","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:47:39.725386Z","iopub.execute_input":"2023-12-14T00:47:39.725656Z","iopub.status.idle":"2023-12-14T00:47:39.732863Z","shell.execute_reply.started":"2023-12-14T00:47:39.725634Z","shell.execute_reply":"2023-12-14T00:47:39.729617Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\naccuracy = accuracy_score(predicted_labels, act_labels)\nreport = classification_report(predicted_labels, act_labels)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:47:39.734419Z","iopub.execute_input":"2023-12-14T00:47:39.734667Z","iopub.status.idle":"2023-12-14T00:47:39.762523Z","shell.execute_reply.started":"2023-12-14T00:47:39.734644Z","shell.execute_reply":"2023-12-14T00:47:39.76169Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Accuracy: 0.5396918275794812\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.73      0.72      0.73      1756\n           1       0.49      0.40      0.44      2095\n           2       0.39      0.51      0.44      1276\n\n    accuracy                           0.54      5127\n   macro avg       0.54      0.55      0.54      5127\nweighted avg       0.55      0.54      0.54      5127\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}